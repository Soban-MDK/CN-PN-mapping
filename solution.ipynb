{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vendor_name = 'SHAH KOTHARI BROS'\n",
    "start_date_pn = '01-09-2024'\n",
    "end_date_pn = '31-12-2024'\n",
    "\n",
    "start_date_cn = '01-09-2024'\n",
    "end_date_cn = '23-01-2025'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>pick_note_number</th>\n",
       "      <th>date</th>\n",
       "      <th>key</th>\n",
       "      <th>ws_code</th>\n",
       "      <th>batch_number</th>\n",
       "      <th>quantity</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>342</td>\n",
       "      <td>J.R.SHAH AND COMPANY</td>\n",
       "      <td>PR201008001</td>\n",
       "      <td>01-10-2024</td>\n",
       "      <td>342_19316_O309</td>\n",
       "      <td>19316</td>\n",
       "      <td>O309</td>\n",
       "      <td>1</td>\n",
       "      <td>Oct-2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356</td>\n",
       "      <td>ATUL MEDICAL AGENCY</td>\n",
       "      <td>PR201008005</td>\n",
       "      <td>01-10-2024</td>\n",
       "      <td>356_4382_K2400513</td>\n",
       "      <td>4382</td>\n",
       "      <td>K2400513</td>\n",
       "      <td>1</td>\n",
       "      <td>Oct-2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>357</td>\n",
       "      <td>DHRUVI HEALTHCARE PVT LTD</td>\n",
       "      <td>PR201008007</td>\n",
       "      <td>01-10-2024</td>\n",
       "      <td>357_1091_BASM036</td>\n",
       "      <td>1091</td>\n",
       "      <td>BASM036</td>\n",
       "      <td>1</td>\n",
       "      <td>Oct-2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>358</td>\n",
       "      <td>B K DISTRIBUTORS</td>\n",
       "      <td>PR201007997</td>\n",
       "      <td>01-10-2024</td>\n",
       "      <td>358_23588_2C29L009</td>\n",
       "      <td>23588</td>\n",
       "      <td>2C29L009</td>\n",
       "      <td>85</td>\n",
       "      <td>Oct-2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359</td>\n",
       "      <td>D K PHARMA</td>\n",
       "      <td>PR201008003</td>\n",
       "      <td>01-10-2024</td>\n",
       "      <td>359_5457_KGA2301A</td>\n",
       "      <td>5457</td>\n",
       "      <td>KGA2301A</td>\n",
       "      <td>1</td>\n",
       "      <td>Oct-2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_id                vendor_name pick_note_number        date  \\\n",
       "0        342       J.R.SHAH AND COMPANY      PR201008001  01-10-2024   \n",
       "1        356        ATUL MEDICAL AGENCY      PR201008005  01-10-2024   \n",
       "2        357  DHRUVI HEALTHCARE PVT LTD      PR201008007  01-10-2024   \n",
       "3        358           B K DISTRIBUTORS      PR201007997  01-10-2024   \n",
       "4        359                 D K PHARMA      PR201008003  01-10-2024   \n",
       "\n",
       "                  key  ws_code batch_number  quantity     month  \n",
       "0      342_19316_O309    19316         O309         1  Oct-2024  \n",
       "1   356_4382_K2400513     4382     K2400513         1  Oct-2024  \n",
       "2    357_1091_BASM036     1091      BASM036         1  Oct-2024  \n",
       "3  358_23588_2C29L009    23588     2C29L009        85  Oct-2024  \n",
       "4   359_5457_KGA2301A     5457     KGA2301A         1  Oct-2024  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn = pd.read_csv('pn_data.csv')\n",
    "pn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_cn_date</th>\n",
       "      <th>debit_note_number</th>\n",
       "      <th>key</th>\n",
       "      <th>billed_quantity</th>\n",
       "      <th>month</th>\n",
       "      <th>vendor_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>DN201005468</td>\n",
       "      <td>388_10098_GEO37697</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep-2024</td>\n",
       "      <td>PHARMA DISTRIBUTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>DN201005466</td>\n",
       "      <td>388_10779_LIL1L00</td>\n",
       "      <td>20</td>\n",
       "      <td>Sep-2024</td>\n",
       "      <td>PHARMA DISTRIBUTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>DN201005468</td>\n",
       "      <td>388_10779_LIL1L00</td>\n",
       "      <td>5</td>\n",
       "      <td>Sep-2024</td>\n",
       "      <td>PHARMA DISTRIBUTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>DN201005468</td>\n",
       "      <td>388_11141_230330040</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep-2024</td>\n",
       "      <td>PHARMA DISTRIBUTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>DN201005468</td>\n",
       "      <td>388_11681_220910719</td>\n",
       "      <td>3</td>\n",
       "      <td>Sep-2024</td>\n",
       "      <td>PHARMA DISTRIBUTOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor_cn_date debit_note_number                  key  billed_quantity  \\\n",
       "0     2024-09-01       DN201005468   388_10098_GEO37697                1   \n",
       "1     2024-09-01       DN201005466    388_10779_LIL1L00               20   \n",
       "2     2024-09-01       DN201005468    388_10779_LIL1L00                5   \n",
       "3     2024-09-01       DN201005468  388_11141_230330040                1   \n",
       "4     2024-09-01       DN201005468  388_11681_220910719                3   \n",
       "\n",
       "      month         vendor_name  \n",
       "0  Sep-2024  PHARMA DISTRIBUTOR  \n",
       "1  Sep-2024  PHARMA DISTRIBUTOR  \n",
       "2  Sep-2024  PHARMA DISTRIBUTOR  \n",
       "3  Sep-2024  PHARMA DISTRIBUTOR  \n",
       "4  Sep-2024  PHARMA DISTRIBUTOR  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn = pd.read_csv('cn_data.csv')\n",
    "cn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn['date'] = pd.to_datetime(pn['date'], format='%d-%m-%Y')\n",
    "cn['vendor_cn_date'] = pd.to_datetime(cn['vendor_cn_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Sort DataFrames\n",
    "pn = pn.sort_values('date')\n",
    "cn = cn.sort_values('vendor_cn_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping completed. Check p_c_r.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_mapping():\n",
    "    # Load and prepare data\n",
    "    pn = pd.read_csv('pn_data.csv')\n",
    "    cn = pd.read_csv('cn_data.csv')\n",
    "    \n",
    "    pn['date'] = pd.to_datetime(pn['date'], format='%d-%m-%Y')\n",
    "    cn['vendor_cn_date'] = pd.to_datetime(cn['vendor_cn_date'])\n",
    "    \n",
    "    pn = pn.sort_values('date')\n",
    "    cn = cn.sort_values('vendor_cn_date')\n",
    "    \n",
    "    mapped_records = []\n",
    "    cn_remaining = defaultdict(dict)  # Track remaining CN quantities by key and date\n",
    "    \n",
    "    # Process each key\n",
    "    for key in pn['key'].unique():\n",
    "        key_pns = pn[pn['key'] == key].copy()\n",
    "        key_cns = cn[cn['key'] == key].copy()\n",
    "        \n",
    "        if key_cns.empty:\n",
    "            continue\n",
    "            \n",
    "        # Initialize CN remainings for this key\n",
    "        for _, cn_row in key_cns.iterrows():\n",
    "            cn_remaining[key][cn_row['vendor_cn_date']] = cn_row['billed_quantity']\n",
    "            \n",
    "        pn_remaining = 0  # Track remaining PN quantity\n",
    "        \n",
    "        for _, pn_row in key_pns.iterrows():\n",
    "            current_pn_qty = pn_row['quantity'] + pn_remaining\n",
    "            \n",
    "            # Find eligible CNs with remaining quantity\n",
    "            eligible_cns = key_cns[\n",
    "                (key_cns['vendor_cn_date'] >= pn_row['date']) & \n",
    "                (key_cns['vendor_cn_date'].map(lambda x: cn_remaining[key][x] > 0))\n",
    "            ].copy()\n",
    "            \n",
    "            if eligible_cns.empty:\n",
    "                pn_remaining = current_pn_qty\n",
    "                continue\n",
    "                \n",
    "            nearest_cn = eligible_cns.iloc[0]\n",
    "            cn_date = nearest_cn['vendor_cn_date']\n",
    "            cn_qty_available = cn_remaining[key][cn_date]\n",
    "            \n",
    "            qty_to_map = min(current_pn_qty, cn_qty_available)\n",
    "            \n",
    "            mapped_records.append({\n",
    "                'PN_Date': pn_row['date'],\n",
    "                'CN_Date': cn_date,\n",
    "                'Pick_Note': pn_row['pick_note_number'],\n",
    "                'Credit_Note': nearest_cn['debit_note_number'],\n",
    "                'Key': key,\n",
    "                'Vendor': pn_row['vendor_name'],\n",
    "                'PN_Qty': qty_to_map,\n",
    "                'CN_Qty': qty_to_map,\n",
    "                'PN_Remaining': current_pn_qty - qty_to_map,\n",
    "                'CN_Remaining': cn_qty_available - qty_to_map,\n",
    "                'Original_PN_Qty': pn_row['quantity'],\n",
    "                'Original_CN_Qty': nearest_cn['billed_quantity']\n",
    "            })\n",
    "            \n",
    "            # Update remaining quantities\n",
    "            cn_remaining[key][cn_date] -= qty_to_map\n",
    "            pn_remaining = current_pn_qty - qty_to_map\n",
    "            \n",
    "    result_df = pd.DataFrame(mapped_records)\n",
    "    result_df['PN_Date'] = result_df['PN_Date'].dt.strftime('%Y-%m-%d')\n",
    "    result_df['CN_Date'] = result_df['CN_Date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    result_df.to_csv('p_c_r.csv', index=False)\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = process_mapping()\n",
    "    print(\"Mapping completed. Check p_c_r.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping completed. Check complete_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_mapping():\n",
    "    # Load and prepare data\n",
    "    pn = pd.read_csv('pn_data.csv')\n",
    "    cn = pd.read_csv('cn_data.csv')\n",
    "    \n",
    "    \n",
    "    pn['date'] = pd.to_datetime(pn['date'], format='%d-%m-%Y')\n",
    "    cn['vendor_cn_date'] = pd.to_datetime(cn['vendor_cn_date'])\n",
    "    \n",
    "    pn = pn.sort_values('date')\n",
    "    cn = cn.sort_values('vendor_cn_date')\n",
    "    \n",
    "    mapped_records = []\n",
    "    used_cn_indices = defaultdict(set)\n",
    "    \n",
    "    # Process each key\n",
    "    for key in pn['key'].unique():\n",
    "        key_pns = pn[pn['key'] == key].copy()\n",
    "        key_cns = cn[cn['key'] == key].copy()\n",
    "        \n",
    "        pn_remaining = 0\n",
    "        \n",
    "        # First pass: Map PNs with available CNs\n",
    "        for idx, pn_row in key_pns.iterrows():\n",
    "            current_pn_qty = pn_row['quantity'] + pn_remaining\n",
    "            \n",
    "            if not key_cns.empty:\n",
    "                eligible_cns = key_cns[\n",
    "                    (key_cns['vendor_cn_date'] >= pn_row['date']) & \n",
    "                    (~key_cns.index.isin(used_cn_indices[key]))\n",
    "                ].copy()\n",
    "                \n",
    "                if not eligible_cns.empty:\n",
    "                    nearest_cn = eligible_cns.iloc[0]\n",
    "                    cn_qty_available = nearest_cn['billed_quantity']\n",
    "                    \n",
    "                    qty_to_map = min(current_pn_qty, cn_qty_available)\n",
    "                    \n",
    "                    mapped_records.append({\n",
    "                        'PN_Date': pn_row['date'],\n",
    "                        'CN_Date': nearest_cn['vendor_cn_date'],\n",
    "                        'Pick_Note': pn_row['pick_note_number'],\n",
    "                        'Credit_Note': nearest_cn['debit_note_number'],\n",
    "                        'Key': key,\n",
    "                        'Vendor': pn_row['vendor_name'],\n",
    "                        'PN_Qty': qty_to_map,\n",
    "                        'CN_Qty': qty_to_map,\n",
    "                        'PN_Remaining': current_pn_qty - qty_to_map,\n",
    "                        'CN_Remaining': cn_qty_available - qty_to_map,\n",
    "                        'Original_PN_Qty': pn_row['quantity'],\n",
    "                        'Original_CN_Qty': nearest_cn['billed_quantity']\n",
    "                    })\n",
    "                    \n",
    "                    used_cn_indices[key].add(nearest_cn.name)\n",
    "                    pn_remaining = current_pn_qty - qty_to_map\n",
    "                    continue\n",
    "            \n",
    "            # Add unmapped PN record\n",
    "            mapped_records.append({\n",
    "                'PN_Date': pn_row['date'],\n",
    "                'CN_Date': None,\n",
    "                'Pick_Note': pn_row['pick_note_number'],\n",
    "                'Credit_Note': None,\n",
    "                'Key': key,\n",
    "                'Vendor': pn_row['vendor_name'],\n",
    "                'PN_Qty': current_pn_qty,\n",
    "                'CN_Qty': 0,\n",
    "                'PN_Remaining': current_pn_qty,\n",
    "                'CN_Remaining': 0,\n",
    "                'Original_PN_Qty': pn_row['quantity'],\n",
    "                'Original_CN_Qty': 0\n",
    "            })\n",
    "        \n",
    "        # Add unmapped CN records\n",
    "        unmapped_cns = key_cns[~key_cns.index.isin(used_cn_indices[key])]\n",
    "        for _, cn_row in unmapped_cns.iterrows():\n",
    "            mapped_records.append({\n",
    "                'PN_Date': None,\n",
    "                'CN_Date': cn_row['vendor_cn_date'],\n",
    "                'Pick_Note': None,\n",
    "                'Credit_Note': cn_row['debit_note_number'],\n",
    "                'Key': key,\n",
    "                'Vendor': cn_row['vendor_name'],\n",
    "                'PN_Qty': 0,\n",
    "                'CN_Qty': cn_row['billed_quantity'],\n",
    "                'PN_Remaining': 0,\n",
    "                'CN_Remaining': cn_row['billed_quantity'],\n",
    "                'Original_PN_Qty': 0,\n",
    "                'Original_CN_Qty': cn_row['billed_quantity']\n",
    "            })\n",
    "    \n",
    "    result_df = pd.DataFrame(mapped_records)\n",
    "    \n",
    "    # Format dates, handling None values\n",
    "    result_df['PN_Date'] = result_df['PN_Date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else ''\n",
    "    )\n",
    "    result_df['CN_Date'] = result_df['CN_Date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else ''\n",
    "    )\n",
    "    \n",
    "    result_df = result_df.sort_values(['Key', 'PN_Date', 'CN_Date'])\n",
    "    result_df.to_csv('pcr_v2.csv', index=False)\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = process_mapping()\n",
    "    print(\"Mapping completed. Check complete_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping completed. Check complete_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "def process_mapping():\n",
    "    # Load data\n",
    "    pn = pd.read_csv('pn_data.csv')\n",
    "    cn = pd.read_csv('cn_data.csv')\n",
    "    \n",
    "    # Clean and convert dates\n",
    "    pn['date'] = pd.to_datetime(pn['date'].replace('-', pd.NaT), format='%d-%m-%Y', errors='coerce')\n",
    "    cn['vendor_cn_date'] = pd.to_datetime(cn['vendor_cn_date'].replace('-', pd.NaT), format='%Y-%m-%d', errors='coerce')\n",
    "    \n",
    "    # Remove invalid dates and sort\n",
    "    pn = pn.dropna(subset=['date']).sort_values(['key', 'date'])\n",
    "    cn = cn.dropna(subset=['vendor_cn_date']).sort_values(['key', 'vendor_cn_date'])\n",
    "    \n",
    "    mapped_records = []\n",
    "    \n",
    "    for key in pn['key'].unique():\n",
    "        key_pns = pn[pn['key'] == key].reset_index(drop=True)\n",
    "        key_cns = cn[cn['key'] == key].reset_index(drop=True)\n",
    "        \n",
    "        pn_qty_remaining = 0\n",
    "        cn_qty_remaining = 0\n",
    "        \n",
    "        max_rows = max(len(key_pns), len(key_cns))\n",
    "        \n",
    "        for i in range(max_rows):\n",
    "            has_pn = i < len(key_pns)\n",
    "            has_cn = i < len(key_cns)\n",
    "            \n",
    "            if has_pn:\n",
    "                pn_row = key_pns.iloc[i]\n",
    "                pn_qty = pn_row['quantity'] + pn_qty_remaining\n",
    "            else:\n",
    "                pn_qty = pn_qty_remaining\n",
    "            \n",
    "            if has_cn:\n",
    "                cn_row = key_cns.iloc[i]\n",
    "                cn_qty = cn_row['billed_quantity'] + cn_qty_remaining\n",
    "            else:\n",
    "                cn_qty = cn_qty_remaining\n",
    "            \n",
    "            # Calculate mapping quantities\n",
    "            qty_to_map = min(pn_qty, cn_qty) if (pn_qty > 0 and cn_qty > 0) else 0\n",
    "            \n",
    "            record = {\n",
    "                'PN_Date': pn_row['date'] if has_pn else None,\n",
    "                'CN_Date': cn_row['vendor_cn_date'] if has_cn else None,\n",
    "                'Pick_Note': pn_row['pick_note_number'] if has_pn else None,\n",
    "                'Credit_Note': cn_row['debit_note_number'] if has_cn else None,\n",
    "                'Key': key,\n",
    "                'Vendor': pn_row['vendor_name'] if has_pn else (cn_row['vendor_name'] if has_cn else None),\n",
    "                'Original_PN_Qty': pn_row['quantity'] if has_pn else 0,\n",
    "                'Original_CN_Qty': cn_row['billed_quantity'] if has_cn else 0,\n",
    "                'PN_Qty': qty_to_map,\n",
    "                'CN_Qty': qty_to_map,\n",
    "                'PN_Remaining': pn_qty - qty_to_map,\n",
    "                'CN_Remaining': cn_qty - qty_to_map\n",
    "            }\n",
    "            \n",
    "            mapped_records.append(record)\n",
    "            \n",
    "            # Update remaining quantities\n",
    "            pn_qty_remaining = pn_qty - qty_to_map if pn_qty - qty_to_map > 0 else 0\n",
    "            cn_qty_remaining = cn_qty - qty_to_map if cn_qty - qty_to_map > 0 else 0\n",
    "    \n",
    "    # Create DataFrame and format dates\n",
    "    result_df = pd.DataFrame(mapped_records)\n",
    "    result_df['PN_Date'] = result_df['PN_Date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else None\n",
    "    )\n",
    "    result_df['CN_Date'] = result_df['CN_Date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else None\n",
    "    )\n",
    "    \n",
    "    result_df.to_csv('mapping_results.csv', index=False)\n",
    "    return result_df\n",
    "\n",
    "# Execute mapping\n",
    "results = process_mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFECT SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_remarks(pn_remaining, cn_remaining):\n",
    "    if pn_remaining == cn_remaining:\n",
    "        return f\"Exact Match\"\n",
    "    \n",
    "    elif pn_remaining > 0:\n",
    "        return f\"PN Exceeds\"\n",
    "    \n",
    "    elif cn_remaining > 0:\n",
    "        return f\"CN Exceeds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_mapping2():\n",
    "    # Load and prepare data\n",
    "    pn = pd.read_csv('pn_data.csv')\n",
    "    cn = pd.read_csv('cn_data.csv')\n",
    "    \n",
    "    # Clean and convert dates\n",
    "    pn['date'] = pd.to_datetime(pn['date'].replace('-', pd.NaT), format='%d-%m-%Y', errors='coerce')\n",
    "    cn['vendor_cn_date'] = pd.to_datetime(cn['vendor_cn_date'].replace('-', pd.NaT), format='%Y-%m-%d', errors='coerce')\n",
    "    \n",
    "    # Remove invalid dates and sort \n",
    "    pn = pn.dropna(subset=['date']).sort_values(['key', 'date'])\n",
    "    cn = cn.dropna(subset=['vendor_cn_date']).sort_values(['key', 'vendor_cn_date'])\n",
    "    \n",
    "    # An array for storing mapped records.\n",
    "\n",
    "    mapped_records = []\n",
    "    \n",
    "    # Get all unique keys from both dataframes. Basically a set with all the possible keys\n",
    "    all_keys = set(pn['key'].unique()) | set(cn['key'].unique())\n",
    "    \n",
    "    # for each key \n",
    "    for key in all_keys:\n",
    "\n",
    "        # Key_pns is a dataframe which stores the entire data of pn corresponding to the current key. Similar is for cns\n",
    "        key_pns = pn[pn['key'] == key].reset_index(drop=True)\n",
    "        key_cns = cn[cn['key'] == key].reset_index(drop=True)\n",
    "        \n",
    "        # Handle key present in only one dataset\n",
    "        if len(key_pns) == 0:\n",
    "            # Key only in CN data\n",
    "            for i in range(len(key_cns)):\n",
    "                cn_row = key_cns.iloc[i]\n",
    "                mapped_records.append({\n",
    "                    'PN_Date': None,\n",
    "                    'CN_Date': cn_row['vendor_cn_date'],\n",
    "                    'Pick_Note': None,\n",
    "                    'Credit_Note': cn_row['debit_note_number'],\n",
    "                    'Key': key,\n",
    "                    'Vendor': cn_row['vendor_name'],\n",
    "                    'Original_PN_Qty': 0,\n",
    "                    'Original_CN_Qty': cn_row['billed_quantity'],\n",
    "                    'PN_Qty': 0,\n",
    "                    'CN_Qty': cn_row['billed_quantity'],\n",
    "                    'PN_Remaining': 0,  # Already 0 since no PN exists\n",
    "                    'CN_Remaining': cn_row['billed_quantity']  # Set remaining to original qty\n",
    "                })\n",
    "            continue\n",
    "            \n",
    "        if len(key_cns) == 0:\n",
    "            # Key only in PN data\n",
    "            for i in range(len(key_pns)):\n",
    "                pn_row = key_pns.iloc[i]\n",
    "                mapped_records.append({\n",
    "                    'PN_Date': pn_row['date'],\n",
    "                    'CN_Date': None,\n",
    "                    'Pick_Note': pn_row['pick_note_number'],\n",
    "                    'Credit_Note': None,\n",
    "                    'Key': key,\n",
    "                    'Vendor': pn_row['vendor_name'],\n",
    "                    'Original_PN_Qty': pn_row['quantity'],\n",
    "                    'Original_CN_Qty': 0,\n",
    "                    'PN_Qty': pn_row['quantity'],\n",
    "                    'CN_Qty': 0,\n",
    "                    'PN_Remaining': pn_row['quantity'],  # Set remaining to original qty\n",
    "                    'CN_Remaining': 0  # Already 0 since no CN exists\n",
    "                })\n",
    "            continue\n",
    "                \n",
    "        # Rest of your existing mapping logic for when key exists in both datasets\n",
    "        pn_qty_remaining = 0\n",
    "        cn_qty_remaining = 0\n",
    "        max_rows = max(len(key_pns), len(key_cns))\n",
    "        \n",
    "        for i in range(max_rows):\n",
    "            has_pn = i < len(key_pns)\n",
    "            has_cn = i < len(key_cns)\n",
    "            \n",
    "            if has_pn:\n",
    "                pn_row = key_pns.iloc[i]\n",
    "                pn_qty = pn_row['quantity'] + pn_qty_remaining\n",
    "            else:\n",
    "                pn_qty = pn_qty_remaining\n",
    "            \n",
    "            if has_cn:\n",
    "                cn_row = key_cns.iloc[i]\n",
    "                cn_qty = cn_row['billed_quantity'] + cn_qty_remaining\n",
    "            else:\n",
    "                cn_qty = cn_qty_remaining\n",
    "            \n",
    "            # Calculate mapping quantities\n",
    "            qty_to_map = min(pn_qty, cn_qty) if (pn_qty > 0 and cn_qty > 0) else 0\n",
    "            \n",
    "            record = {\n",
    "                'PN_Date': pn_row['date'] if has_pn else None,\n",
    "                'CN_Date': cn_row['vendor_cn_date'] if has_cn else None,\n",
    "                'Pick_Note': pn_row['pick_note_number'] if has_pn else None,\n",
    "                'Credit_Note': cn_row['debit_note_number'] if has_cn else None,\n",
    "                'Key': key,\n",
    "                'Vendor': pn_row['vendor_name'] if has_pn else (cn_row['vendor_name'] if has_cn else None),\n",
    "                'Original_PN_Qty': pn_row['quantity'] if has_pn else 0,\n",
    "                'Original_CN_Qty': cn_row['billed_quantity'] if has_cn else 0,\n",
    "                'PN_Qty': qty_to_map,\n",
    "                'CN_Qty': qty_to_map,\n",
    "                'PN_Remaining': pn_qty - qty_to_map,\n",
    "                'CN_Remaining': cn_qty - qty_to_map\n",
    "            }                                                                                                      \n",
    "            \n",
    "            mapped_records.append(record)\n",
    "            \n",
    "            # Update remaining quantities\n",
    "            pn_qty_remaining = pn_qty - qty_to_map if pn_qty - qty_to_map > 0 else 0\n",
    "            cn_qty_remaining = cn_qty - qty_to_map if cn_qty - qty_to_map > 0 else 0\n",
    "    \n",
    "    # Create DataFrame and format dates\n",
    "    result_df = pd.DataFrame(mapped_records)\n",
    "    result_df['PN_Date'] = result_df['PN_Date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else None\n",
    "    )\n",
    "    result_df['CN_Date'] = result_df['CN_Date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else None\n",
    "    )\n",
    "\n",
    "    # Now create a new column named Remarks which would have value in string format and take value depending on the function add_remarks\n",
    "    result_df['Remarks'] = result_df.apply(lambda x: add_remarks(x['PN_Remaining'], x['CN_Remaining']), axis=1)\n",
    "    \n",
    "    result_df.to_csv('complete_mapping.csv', index=False)\n",
    "    return result_df\n",
    "\n",
    "results = process_mapping2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_mapping2():\n",
    "    # Load and prepare data\n",
    "    pn = pd.read_csv('pn_data.csv')\n",
    "    cn = pd.read_csv('cn_data.csv')\n",
    "    \n",
    "    # Clean and convert dates\n",
    "    pn['date'] = pd.to_datetime(pn['date'].replace('-', pd.NaT), format='%d-%m-%Y', errors='coerce')\n",
    "    cn['vendor_cn_date'] = pd.to_datetime(cn['vendor_cn_date'].replace('-', pd.NaT), format='%Y-%m-%d', errors='coerce')\n",
    "    \n",
    "    # Remove invalid dates and sort \n",
    "    pn = pn.dropna(subset=['date']).sort_values(['key', 'date'])\n",
    "    cn = cn.dropna(subset=['vendor_cn_date']).sort_values(['key', 'vendor_cn_date'])\n",
    "    \n",
    "    # An array for storing mapped records.\n",
    "    mapped_records = []\n",
    "    \n",
    "    # Get all unique keys from both dataframes. Basically a set with all the possible keys\n",
    "    all_keys = set(pn['key'].unique()) | set(cn['key'].unique())\n",
    "    \n",
    "    # for each key \n",
    "    for key in all_keys:\n",
    "\n",
    "        # Key_pns is a dataframe which stores the entire data of pn corresponding to the current key. Similar is for cns\n",
    "        key_pns = pn[pn['key'] == key].reset_index(drop=True)\n",
    "        key_cns = cn[cn['key'] == key].reset_index(drop=True)\n",
    "        \n",
    "        # Handle key present in only one dataset\n",
    "        if len(key_pns) == 0:\n",
    "            # Key only in CN data\n",
    "            for i in range(len(key_cns)):\n",
    "                cn_row = key_cns.iloc[i]\n",
    "                mapped_records.append({\n",
    "                    'PN_Date': None,\n",
    "                    'CN_Date': cn_row['vendor_cn_date'],\n",
    "                    'Pick_Note': None,\n",
    "                    'Credit_Note': cn_row['debit_note_number'],\n",
    "                    'Key': key,\n",
    "                    'Vendor': cn_row['vendor_name'],\n",
    "                    'Original_PN_Qty': 0,\n",
    "                    'Original_CN_Qty': cn_row['billed_quantity'],\n",
    "                    'PN_Qty': 0,\n",
    "                    'CN_Qty': cn_row['billed_quantity'],\n",
    "                    'PN_Remaining': 0,  # Already 0 since no PN exists\n",
    "                    'CN_Remaining': cn_row['billed_quantity']  # Set remaining to original qty\n",
    "                })\n",
    "            continue\n",
    "            \n",
    "        if len(key_cns) == 0:\n",
    "            # Key only in PN data\n",
    "            for i in range(len(key_pns)):\n",
    "                pn_row = key_pns.iloc[i]\n",
    "                mapped_records.append({\n",
    "                    'PN_Date': pn_row['date'],\n",
    "                    'CN_Date': None,\n",
    "                    'Pick_Note': pn_row['pick_note_number'],\n",
    "                    'Credit_Note': None,\n",
    "                    'Key': key,\n",
    "                    'Vendor': pn_row['vendor_name'],\n",
    "                    'Original_PN_Qty': pn_row['quantity'],\n",
    "                    'Original_CN_Qty': 0,\n",
    "                    'PN_Qty': pn_row['quantity'],\n",
    "                    'CN_Qty': 0,\n",
    "                    'PN_Remaining': pn_row['quantity'],  # Set remaining to original qty\n",
    "                    'CN_Remaining': 0  # Already 0 since no CN exists\n",
    "                })\n",
    "            continue\n",
    "                \n",
    "        # Rest of your existing mapping logic for when key exists in both datasets\n",
    "        pn_qty_remaining = 0\n",
    "        cn_qty_remaining = 0\n",
    "        max_rows = max(len(key_pns), len(key_cns))\n",
    "        \n",
    "        pick_notes = []\n",
    "        credit_notes = []\n",
    "        \n",
    "        for i in range(max_rows):\n",
    "            has_pn = i < len(key_pns)\n",
    "            has_cn = i < len(key_cns)\n",
    "            \n",
    "            if has_pn:\n",
    "                pn_row = key_pns.iloc[i]\n",
    "                pn_qty = pn_row['quantity'] + pn_qty_remaining\n",
    "                pick_notes.append(pn_row['pick_note_number'])\n",
    "            else:\n",
    "                pn_qty = pn_qty_remaining\n",
    "            \n",
    "            if has_cn:\n",
    "                cn_row = key_cns.iloc[i]\n",
    "                cn_qty = cn_row['billed_quantity'] + cn_qty_remaining\n",
    "                credit_notes.append(cn_row['debit_note_number'])\n",
    "            else:\n",
    "                cn_qty = cn_qty_remaining\n",
    "            \n",
    "            # Calculate mapping quantities\n",
    "            qty_to_map = min(pn_qty, cn_qty) if (pn_qty > 0 and cn_qty > 0) else 0\n",
    "            \n",
    "            record = {\n",
    "                'PN_Date': pn_row['date'] if has_pn else None,\n",
    "                'CN_Date': cn_row['vendor_cn_date'] if has_cn else None,\n",
    "                'Pick_Note': pick_notes.copy() if has_pn else None,\n",
    "                'Credit_Note': credit_notes.copy() if has_cn else None,\n",
    "                'Key': key,\n",
    "                'Vendor': pn_row['vendor_name'] if has_pn else (cn_row['vendor_name'] if has_cn else None),\n",
    "                'Original_PN_Qty': pn_row['quantity'] if has_pn else 0,\n",
    "                'Original_CN_Qty': cn_row['billed_quantity'] if has_cn else 0,\n",
    "                'PN_Qty': qty_to_map,\n",
    "                'CN_Qty': qty_to_map,\n",
    "                'PN_Remaining': pn_qty - qty_to_map,\n",
    "                'CN_Remaining': cn_qty - qty_to_map\n",
    "            }\n",
    "            \n",
    "            mapped_records.append(record)\n",
    "            \n",
    "            # Update remaining quantities\n",
    "            pn_qty_remaining = pn_qty - qty_to_map if pn_qty - qty_to_map > 0 else 0\n",
    "            cn_qty_remaining = cn_qty - qty_to_map if cn_qty - qty_to_map > 0 else 0\n",
    "            \n",
    "            # Remove used pick notes and credit notes\n",
    "            if pn_qty_remaining == 0:\n",
    "                pick_notes = []\n",
    "            if cn_qty_remaining == 0:\n",
    "                credit_notes = []\n",
    "    \n",
    "    # Create DataFrame and format dates\n",
    "    result_df = pd.DataFrame(mapped_records)\n",
    "    result_df['PN_Date'] = result_df['PN_Date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else None\n",
    "    )\n",
    "    result_df['CN_Date'] = result_df['CN_Date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else None\n",
    "    )\n",
    "\n",
    "    # Now create a new column named Remarks which would have value in string format and take value depending on the function add_remarks\n",
    "    result_df['Remarks'] = result_df.apply(lambda x: add_remarks(x['PN_Remaining'], x['CN_Remaining']), axis=1)\n",
    "    \n",
    "    result_df.to_csv('complete_mapping2.csv', index=False)\n",
    "    return result_df\n",
    "\n",
    "results = process_mapping2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
