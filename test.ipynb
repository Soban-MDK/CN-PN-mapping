{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PN_Date</th>\n",
       "      <th>CN_Date</th>\n",
       "      <th>Pick_Note</th>\n",
       "      <th>Credit_Note</th>\n",
       "      <th>Key</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>PN_Qty</th>\n",
       "      <th>CN_Qty</th>\n",
       "      <th>PN_Remaining</th>\n",
       "      <th>CN_Remaining</th>\n",
       "      <th>Original_PN_Qty</th>\n",
       "      <th>Original_CN_Qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>PR201008895</td>\n",
       "      <td>DN201006195</td>\n",
       "      <td>322_11299_SIF1190A</td>\n",
       "      <td>AHMEDABAD MEDICAL CORPORATION</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>PR201008882</td>\n",
       "      <td>DN201006163</td>\n",
       "      <td>322_11303_SIF1510A</td>\n",
       "      <td>AHMEDABAD MEDICAL CORPORATION</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-16</td>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>PR201008755</td>\n",
       "      <td>DN201006186</td>\n",
       "      <td>322_1178_FHA0249</td>\n",
       "      <td>AHMEDABAD MEDICAL CORPORATION</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>PR201009347</td>\n",
       "      <td>DN201006646</td>\n",
       "      <td>322_13460_SIF1920A</td>\n",
       "      <td>AHMEDABAD MEDICAL CORPORATION</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>PR201008535</td>\n",
       "      <td>DN201006186</td>\n",
       "      <td>322_13492_BA31427</td>\n",
       "      <td>AHMEDABAD MEDICAL CORPORATION</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PN_Date     CN_Date    Pick_Note  Credit_Note                 Key  \\\n",
       "0  2024-11-23  2024-11-25  PR201008895  DN201006195  322_11299_SIF1190A   \n",
       "1  2024-11-20  2024-11-22  PR201008882  DN201006163  322_11303_SIF1510A   \n",
       "2  2024-11-16  2024-11-19  PR201008755  DN201006186    322_1178_FHA0249   \n",
       "3  2024-12-28  2024-12-28  PR201009347  DN201006646  322_13460_SIF1920A   \n",
       "4  2024-11-06  2024-11-19  PR201008535  DN201006186   322_13492_BA31427   \n",
       "\n",
       "                          Vendor  PN_Qty  CN_Qty  PN_Remaining  CN_Remaining  \\\n",
       "0  AHMEDABAD MEDICAL CORPORATION     1.0     1.0           0.0           0.0   \n",
       "1  AHMEDABAD MEDICAL CORPORATION     1.0     1.0           0.0           0.0   \n",
       "2  AHMEDABAD MEDICAL CORPORATION     6.0     6.0           0.0           0.0   \n",
       "3  AHMEDABAD MEDICAL CORPORATION     6.0     6.0           0.0           0.0   \n",
       "4  AHMEDABAD MEDICAL CORPORATION     1.0     1.0           0.0           0.0   \n",
       "\n",
       "   Original_PN_Qty  Original_CN_Qty  \n",
       "0                1              1.0  \n",
       "1                1              1.0  \n",
       "2                6              6.0  \n",
       "3                6              6.0  \n",
       "4                1              1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn_cn = pd.read_csv('./pcr_v2.csv')\n",
    "pn_cn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using value_counts() to count the occurence of each key of the key column in the pn_cn DataFrame and take out each key with occurence greater than 1.\n",
    "\n",
    "X = pn_cn['Key'].value_counts()[pn_cn['Key'].value_counts() > 2]\n",
    "\n",
    "# Saving to a text file\n",
    "X.to_csv('keys.txt', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_cn.to_csv(\"MultiKey.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_mapping2():\n",
    "    # Load and prepare data\n",
    "    pn = pd.read_csv('pn_data.csv')\n",
    "    cn = pd.read_csv('cn_data.csv')\n",
    "    \n",
    "    # Clean and convert dates\n",
    "    pn['date'] = pd.to_datetime(pn['date'].replace('-', pd.NaT), format='%d-%m-%Y', errors='coerce')\n",
    "    cn['vendor_cn_date'] = pd.to_datetime(cn['vendor_cn_date'].replace('-', pd.NaT), format='%Y-%m-%d', errors='coerce')\n",
    "    \n",
    "    # Remove invalid dates and sort \n",
    "    pn = pn.dropna(subset=['date']).sort_values(['key', 'date'])\n",
    "    cn = cn.dropna(subset=['vendor_cn_date']).sort_values(['key', 'vendor_cn_date'])\n",
    "    \n",
    "    \n",
    "\n",
    "    # An array for storing mapped records.\n",
    "    mapped_records = []\n",
    "    \n",
    "    # Get all unique keys from both dataframes. Basically a set with all the possible keys\n",
    "    all_keys = set(pn['key'].unique()) | set(cn['key'].unique())\n",
    "    \n",
    "    # for each key \n",
    "    for key in all_keys:\n",
    "\n",
    "        # Key_pns is a dataframe which stores the entire data of pn corresponding to the current key. Similar is for cns\n",
    "        key_pns = pn[pn['key'] == key].reset_index(drop=True)\n",
    "        key_cns = cn[cn['key'] == key].reset_index(drop=True)\n",
    "        \n",
    "        # Handle key present in only one dataset\n",
    "        if len(key_pns) == 0:\n",
    "            # Key only in CN data\n",
    "            for i in range(len(key_cns)):\n",
    "                cn_row = key_cns.iloc[i]\n",
    "                mapped_records.append({\n",
    "                    'PN_Date': None,\n",
    "                    'CN_Date': cn_row['vendor_cn_date'],\n",
    "                    'Pick_Note': None,\n",
    "                    'Credit_Note': cn_row['debit_note_number'],\n",
    "                    'Key': key,\n",
    "                    'Vendor': cn_row['vendor_name'],\n",
    "                    'Original_PN_Qty': 0,\n",
    "                    'Original_CN_Qty': cn_row['billed_quantity'],\n",
    "                    'PN_Qty': 0,\n",
    "                    'CN_Qty': cn_row['billed_quantity'],\n",
    "                    'PN_Remaining': 0,  # Already 0 since no PN exists\n",
    "                    'CN_Remaining': cn_row['billed_quantity']  # Set remaining to original qty\n",
    "                })\n",
    "            continue\n",
    "            \n",
    "        if len(key_cns) == 0:\n",
    "            # Key only in PN data\n",
    "            for i in range(len(key_pns)):\n",
    "                pn_row = key_pns.iloc[i]\n",
    "                mapped_records.append({\n",
    "                    'PN_Date': pn_row['date'],\n",
    "                    'CN_Date': None,\n",
    "                    'Pick_Note': pn_row['pick_note_number'],\n",
    "                    'Credit_Note': None,\n",
    "                    'Key': key,\n",
    "                    'Vendor': pn_row['vendor_name'],\n",
    "                    'Original_PN_Qty': pn_row['quantity'],\n",
    "                    'Original_CN_Qty': 0,\n",
    "                    'PN_Qty': pn_row['quantity'],\n",
    "                    'CN_Qty': 0,\n",
    "                    'PN_Remaining': pn_row['quantity'],  # Set remaining to original qty\n",
    "                    'CN_Remaining': 0  # Already 0 since no CN exists\n",
    "                })\n",
    "            continue\n",
    "                \n",
    "        # Rest of your existing mapping logic for when key exists in both datasets\n",
    "        pn_qty_remaining = 0\n",
    "        cn_qty_remaining = 0\n",
    "        max_rows = max(len(key_pns), len(key_cns))\n",
    "        \n",
    "        pick_notes = []\n",
    "        credit_notes = []\n",
    "        \n",
    "        for i in range(max_rows):\n",
    "            has_pn = i < len(key_pns)\n",
    "            has_cn = i < len(key_cns)\n",
    "            \n",
    "            if has_pn:\n",
    "                pn_row = key_pns.iloc[i]\n",
    "                pn_qty = pn_row['quantity'] + pn_qty_remaining\n",
    "                pick_notes.append(pn_row['pick_note_number'])\n",
    "            else:\n",
    "                pn_qty = pn_qty_remaining\n",
    "            \n",
    "            if has_cn:\n",
    "                cn_row = key_cns.iloc[i]\n",
    "                cn_qty = cn_row['billed_quantity'] + cn_qty_remaining\n",
    "                credit_notes.append(cn_row['debit_note_number'])\n",
    "            else:\n",
    "                cn_qty = cn_qty_remaining\n",
    "            \n",
    "            # Calculate mapping quantities\n",
    "            qty_to_map = min(pn_qty, cn_qty) if (pn_qty > 0 and cn_qty > 0) else 0\n",
    "            \n",
    "            record = {\n",
    "                'PN_Date': pn_row['date'] if has_pn else None,\n",
    "                'CN_Date': cn_row['vendor_cn_date'] if has_cn else None,\n",
    "                'Pick_Note': pick_notes.copy() if has_pn else None,\n",
    "                'Credit_Note': credit_notes.copy() if has_cn else None,\n",
    "                'Key': key,\n",
    "                'Vendor': pn_row['vendor_name'] if has_pn else (cn_row['vendor_name'] if has_cn else None),\n",
    "                'Original_PN_Qty': pn_row['quantity'] if has_pn else 0,\n",
    "                'Original_CN_Qty': cn_row['billed_quantity'] if has_cn else 0,\n",
    "                'PN_Qty': qty_to_map,\n",
    "                'CN_Qty': qty_to_map,\n",
    "                'PN_Remaining': pn_qty - qty_to_map,\n",
    "                'CN_Remaining': cn_qty - qty_to_map\n",
    "            }\n",
    "            \n",
    "            mapped_records.append(record)\n",
    "            \n",
    "            # Update remaining quantities\n",
    "            pn_qty_remaining = pn_qty - qty_to_map if pn_qty - qty_to_map > 0 else 0\n",
    "            cn_qty_remaining = cn_qty - qty_to_map if cn_qty - qty_to_map > 0 else 0\n",
    "            \n",
    "            # Remove used pick notes and credit notes\n",
    "            if pn_qty_remaining == 0:\n",
    "                pick_notes = []\n",
    "            if cn_qty_remaining == 0:\n",
    "                credit_notes = []\n",
    "    \n",
    "    # Create DataFrame and format dates\n",
    "    result_df = pd.DataFrame(mapped_records)\n",
    "    result_df['PN_Date'] = result_df['PN_Date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else None\n",
    "    )\n",
    "    result_df['CN_Date'] = result_df['CN_Date'].apply(\n",
    "        lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else None\n",
    "    )\n",
    "\n",
    "    # Now create a new column named Remarks which would have value in string format and take value depending on the function add_remarks\n",
    "    result_df['Remarks'] = result_df.apply(lambda x: add_remarks(x['PN_Remaining'], x['CN_Remaining']), axis=1)\n",
    "    \n",
    "    result_df.to_csv('complete_mapping2.csv', index=False)\n",
    "    return result_df\n",
    "\n",
    "results = process_mapping2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
